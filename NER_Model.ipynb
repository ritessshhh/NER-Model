{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9HC9Yzin6AY"
      },
      "source": [
        "# Dataset\n",
        "\n",
        "You will use the data introduced by the Language-Independent Named Entity Recognition tasks, through the following body of work:\n",
        "\n",
        "* Erik F. Tjong Kim Sang and Fien De Meulder. 2003. [Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition](https://aclanthology.org/W03-0419/). In *Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003*, pages 142--147.\n",
        "* Erik F. Tjong Kim Sang. 2002. [Introduction to the CoNLL-2002 Shared Task: Language-Independent Named Entity Recognition](https://aclanthology.org/W02-2024/). In *COLING-02: The 6th Conference on Natural Language Learning 2002 (CoNLL-2002)*.\n",
        "\n",
        "This assignment, however, is restricted to NER in the English language only, and the dataset consists of three files:\n",
        "\n",
        "1. `eng.train`, for training\n",
        "2. `eng.testa`, as the development set\n",
        "3. `eng.testb`, as the final test set\n",
        "\n",
        "These files can be downloaded as a single `.zip` [here](https://drive.google.com/file/d/15YEXQlDk8wvqAFOE1chaS_PYvMaLGUGX/view?usp=sharing)\n",
        "\n",
        "To avoid any complications, you should take advantage of the fact that the total amount of data is much smaller than the previous assignment, and store the entire dataset in your own Google Drive. To do this, connect your Drive to your Colab notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fS8B-nSbxXDD",
        "outputId": "7bb41a90-8935-40fd-cab6-0be2b7c64b7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount ('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9WhzU4Y0eBp"
      },
      "source": [
        "Then, unzip the dataset (**remember to change the path to where you have stored it in your own Google drive**):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycsn8ON9yh9S",
        "outputId": "333f1ce5-2b5e-4fc1-d825-ae2a96fac6b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open /content/drive/MyDrive/courses/cse354/eng-ner-dataset.zip, /content/drive/MyDrive/courses/cse354/eng-ner-dataset.zip.zip or /content/drive/MyDrive/courses/cse354/eng-ner-dataset.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!unzip /content/drive/MyDrive/courses/cse354/eng-ner-dataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MP38Yo0V0jTC"
      },
      "source": [
        "At this point, you have the unzipped corpus (with the three files) as the `eng-ner-dataset` folder accessible to your Colab notebook. The format of this data is probably new to you, so the first thing to do is to use the `head` command and see what the data looks like ([see this man page](https://www.gnu.org/software/coreutils/manual/html_node/head-invocation.html) for the details of its syntax). For example, you can view the top 20 lines of the `eng.train` file as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1L51bkN1Xhr",
        "outputId": "8a03c0de-6bb5-42c3-c25c-dc02d54aab0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EU NNP I-NP I-ORG\n",
            "rejects VBZ I-VP O\n",
            "German JJ I-NP I-MISC\n",
            "call NN I-NP O\n",
            "to TO I-VP O\n",
            "boycott VB I-VP O\n",
            "British JJ I-NP I-MISC\n",
            "lamb NN I-NP O\n",
            ". . O O\n",
            "\n",
            "Peter NNP I-NP I-PER\n",
            "Blackburn NNP I-NP I-PER\n",
            "\n",
            "BRUSSELS NNP I-NP I-LOC\n",
            "1996-08-22 CD I-NP O\n",
            "\n",
            "The DT I-NP O\n",
            "European NNP I-NP I-ORG\n",
            "Commission NNP I-NP I-ORG\n",
            "said VBD I-VP O\n"
          ]
        }
      ],
      "source": [
        "!head -n 20 /content/drive/MyDrive/eng-ner-dataset/eng.train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHyJwQfi29pC"
      },
      "source": [
        "The format you see is known as the [IOB format](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)), popularly used in many NLP tasks since the CoNLL 2003 NER tasks. The file format requires\n",
        "\n",
        "- each token has to be on a separate line\n",
        "- there must be an empty line after each sentence\n",
        "- a line must contain at least two columns: first, the token itself; and the last, the named entity\n",
        "\n",
        "It doesn't matter if there are extra columns in between (perhaps containing part-of-speech tag or other information), as long as the named entity information is given in the IOB format (either IOB or IOB2).\n",
        "\n",
        "**Note:** There is a slight difference between the original IOB and IOB2 formats, and you may need to convert the training and test data to IOB2 (if you spot that some instances are using IOB while others are using IOB2)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1OkT1VS507E"
      },
      "source": [
        "# Task Overview\n",
        "\n",
        "The programming involves three stages:\n",
        "\n",
        "1. converting the text data into feature vectors, so that it can readily be used by supervised machine learning algorithms,\n",
        "2. implement your own logistic regression classifier to identify whether or not a token is part of a person's name, and\n",
        "3. implement your own multinomial logistic regression classifier to develop a complete NER system.\n",
        "\n",
        "Throughout this assignment, remember to use type annotations in your Python code. Even if you are unable to do this for variables whose data types are dependent on external libraries that are allowed in this assignment (specified later), don't forget the type annotations for the core data types. These annotations are already provided to you in the method signatures from this point onward (to illustrate how to do this, as well as to specify the method signatures required by this assignment).\n",
        "\n",
        "* Feel free to import additional types as needed (see the line below, where a few data types are already imported for such type annotations: `from typing import ...`).\n",
        "\n",
        "#### 1.1 Importing required libraries\n",
        "- You may import modules from core Python\n",
        "- You may use any modules from `numpy` and `pandas` as long as it does not involve any 'outsourcing' of machine learning algorithms to these modules.\n",
        "\n",
        "**Do not add the following dependencies:**\n",
        "- Any module from NLTK\n",
        "- Any module from SciPy\n",
        "- Any module from scikit-learn (i.e., `sklearn`) unless it is already provided to you in this Colab notebook\n",
        "- Any library/module that performs optimizations (minimization or maximization of a function) for you. Purely numeric calculations that arise from mathematics (outside the topics in this assignment) can be done by calling numpy functions, but you must implement the stochastic gradient descent algorithm on your own.\n",
        "  - For example, computing a dot product can be done using numpy, but logits, sigmoid, softmax, etc. must be your own implementation.\n",
        "\n",
        "**What about additional methods, variables, data structures, etc.?**\n",
        "\n",
        "Throughout this assignment, you may add any number of helper methods, as you feel the need to do so. Similarly, you may use additional variables and/or data structures as the need arises. For example, if your implementation of the classifier requires you to add a class attribute, you can certainly do that.\n",
        "\n",
        "However, please keep in mind three things:\n",
        "\n",
        "1. Any external user should remain oblivious to any such additional function or variable (i.e., they should not have to assume or figure out things beyond what is already given, in order to run your code).\n",
        "2. You must update the docstring of a class if you are introducing any additional attribute.\n",
        "3. Any additional method that you write (say, a helper method) must also have a proper docstring and type hint/annotation for its signature (i.e., what data types it expects as parameters, and what data type it returns)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnzQvHI86ymF"
      },
      "source": [
        "# Data Preparation [20 points]\n",
        "\n",
        "The first step is to make sure that your code is able to read the data one sentence at a time. Given the number of sentences, and that you may have to do analyze or process each sentence in computationally complex ways, it is always prudent in this kind of work to write your code in a ways that avoids loading the entire training set. In this assignment, it may be possible, but the better option is to use the *generator* idea in Python. In this approach, the sentences are generated one at a time in a *lazy* manner (if you are more familiar with Java, think `Stream` insted of `List`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E92KY0zA6xVR"
      },
      "outputs": [],
      "source": [
        "import re, pandas, numpy\n",
        "from typing import Dict, Iterator, List, TextIO, Tuple\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "UNKNOWN_TOKEN = 'UNK'  # This will be needed at times, so let's just declare it as a global constant right away\n",
        "\n",
        "def load_instances(iob_file: TextIO, sep: str = '\\n') -> Iterator[str]:\n",
        "    \"\"\"\n",
        "    Load instances (which are sentences) from an input file stream.\n",
        "\n",
        "    This function reads an input file stream (`iob_file`), where tokenized sentences are provided in the IOB or IOB2\n",
        "    format, which requires each token to be on a separate line, and that there is an empty line after each sentence.\n",
        "    This empty line acts as the default separator (`sep`). Each yielded instance is a single annotated sentence (in the\n",
        "    IOB or IOB2 format, as given in the input file).\n",
        "\n",
        "    Parameters:\n",
        "        iob_file (TextIO): An input file stream containing annotated text data.\n",
        "        sep (str, optional): The separator used to separate instances. Defaults to '\\\\n'.\n",
        "\n",
        "    Yields:\n",
        "        str: A string representing a single (tokenized and annotated) sentence.\n",
        "    \"\"\"\n",
        "    # TODO\n",
        "    sentence = []\n",
        "    for line in iob_file:\n",
        "        line = line.strip()\n",
        "        if line:\n",
        "            sentence.append(line)\n",
        "        else:\n",
        "            if sentence:\n",
        "                yield ' '.join(sentence)\n",
        "                sentence = []\n",
        "    if sentence:\n",
        "        yield ' '.join(sentence)\n",
        "\n",
        "def convert_to_iob2(sentence: str) -> str:\n",
        "    \"\"\"\n",
        "    Convert a sentence from IOB to IOB2 format.\n",
        "    \"\"\"\n",
        "    previous_tag = \"O\"\n",
        "    converted_sentence = []\n",
        "    for token in sentence.split(' '):\n",
        "        parts = token.rsplit(' ', 1)  # Split each token from its tag\n",
        "        if len(parts) == 2:\n",
        "            word, tag = parts\n",
        "            if tag.startswith(\"I-\") and (previous_tag == \"O\" or previous_tag[2:] != tag[2:]):\n",
        "                # Convert I- to B- if previous tag is O or different entity type\n",
        "                tag = \"B\" + tag[1:]\n",
        "            converted_sentence.append(f\"{word} {tag}\")\n",
        "            previous_tag = tag\n",
        "        else:\n",
        "            converted_sentence.append(token)\n",
        "            previous_tag = \"O\"  # Reset for non-tagged tokens\n",
        "    return '\\n'.join(converted_sentence)\n",
        "\n",
        "def process_file(input_file_path: Path, output_file_path: Path) -> None:\n",
        "    \"\"\"\n",
        "    Process the given file from IOB to IOB2 format and save the output.\n",
        "    \"\"\"\n",
        "    with input_file_path.open('r', encoding='utf-8') as input_file:\n",
        "        sentences = load_instances(input_file)\n",
        "        with output_file_path.open('w', encoding='utf-8') as output_file:\n",
        "            for sentence in sentences:\n",
        "                converted_sentence = convert_to_iob2(sentence)\n",
        "                output_file.write(converted_sentence + \"\\n\\n\")  # Add extra newline to separate sentences\n",
        "\n",
        "input_path = Path('/content/drive/MyDrive/eng-ner-dataset/eng.train')  # Adjust path as necessary\n",
        "output_path = Path('/content/drive/MyDrive/eng-ner-dataset/engIOB2.train')\n",
        "process_file(input_path, output_path)\n",
        "\n",
        "input_path = Path('/content/drive/MyDrive/eng-ner-dataset/eng.testa')  # Adjust path as necessary\n",
        "output_path = Path('/content/drive/MyDrive/eng-ner-dataset/engIOB2.testa')\n",
        "process_file(input_path, output_path)\n",
        "\n",
        "input_path = Path('/content/drive/MyDrive/eng-ner-dataset/eng.testb')  # Adjust path as necessary\n",
        "output_path = Path('/content/drive/MyDrive/eng-ner-dataset/engIOB2.testb')\n",
        "process_file(input_path, output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eptfyAl45ofU",
        "outputId": "9914bc93-980a-4247-a832-391ea0b9ef01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EU NNP I-NP I-ORG rejects VBZ I-VP O German JJ I-NP I-MISC call NN I-NP O to TO I-VP O boycott VB I-VP O British JJ I-NP I-MISC lamb NN I-NP O . . O O\n"
          ]
        }
      ],
      "source": [
        "with open(\"/content/drive/MyDrive/eng-ner-dataset/engIOB2.train\") as file:\n",
        "  for line in load_instances(file):\n",
        "    print(line)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvYrxovu62fp"
      },
      "source": [
        "Building the feature vectors will require the use of tokens seen in the training data, as well as other properties such as the part-of-speech (POS) tags of these tokens. Thus, it is imperative that all such tokens and POS tags are properly collected and tracked. The next method should help you do just that.\n",
        "\n",
        "> ---\n",
        "> **Optional features: phrasal information**\n",
        ">\n",
        "> You may have already noticed that the annotated data also contains information about the phrase containing a token (again, in IOB or IOB2 format). You are welcome to build features out of this information as well, although this is not mandated by the assignment. If you want to do this, we strongly suggest that you investigate this only *after* finishing everything else.\n",
        ">\n",
        "> *Phrasal information* is encoded as whether a token is a part of a noun phrase (NP), verb phrase (VP), prepositional phrase (PP), adjective/adverb phrases (ADJP/ADVP), verb particles (PRT), interjections (INTJ), and clauses introduced by a subordinating conjunction (SBAR).\n",
        ">\n",
        "> * If you are interested, you can read more about it [here](https://aclanthology.org/W00-0726.pdf).\n",
        ">\n",
        "> If you want to include features based on this phrase-level annotation, and want to add a third dictionary to the return type of the following function, please mention it very clearly in the docstring, and also modify the docstring to reflect this updated use of the `get_vocabulary` method.\n",
        ">\n",
        "> ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCmSkrgS5aCT"
      },
      "outputs": [],
      "source": [
        "def get_vocabulary(training_file: str) -> Tuple[Dict[str, int], Dict[str, int]]:\n",
        "    \"\"\"\n",
        "    Create a vocabulary of lowercase tokens and part-of-speech (POS) tags from a training file, associating each token\n",
        "    and each POS with a unique index.\n",
        "\n",
        "    This function reads the specified training file, extracts tokens and POS tags from each sentence. It then converts\n",
        "    the tokens to lowercase, and associates each lowercase token with a unique index. It also associates each POS with\n",
        "    a unique index. The result is returned as a pair of dictionaries.\n",
        "\n",
        "    Parameters:\n",
        "        training_file (str): The path to the training file containing annotated text data.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[Dict[str, int], Dict[str, int]]: A pair of dictionaries where the first dictionary consists of keys that\n",
        "        are lowercase tokens and values are their corresponding indices; and the second dictionary consists of keys that\n",
        "        are part-of-speech tags and values are their corresponding indices.\n",
        "\n",
        "    Raises:\n",
        "        IOError: If the specified training file cannot be opened or read.\n",
        "    \"\"\"\n",
        "    # TODO\n",
        "    tokens = {}\n",
        "    pos_tags = {}\n",
        "    token_index = 0\n",
        "    pos_index = 0\n",
        "\n",
        "    try:\n",
        "      with open(training_file, 'r') as file:\n",
        "          for line in load_instances(file):\n",
        "              line = line.strip().split()\n",
        "              line_tokens = [tok.lower() for tok in line[::4]]  # Convert tokens to lowercase\n",
        "              line_pos_tags = line[1::4]\n",
        "              for tok, pos in zip(line_tokens, line_pos_tags):\n",
        "                  if tok not in tokens:\n",
        "                      tokens[tok] = token_index\n",
        "                      token_index += 1\n",
        "                  if pos not in pos_tags:\n",
        "                      pos_tags[pos] = pos_index\n",
        "                      pos_index += 1\n",
        "    except:\n",
        "      raise FileNotFoundError(f\"File cannot be opened or read.\")\n",
        "\n",
        "    return (tokens, pos_tags)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WM2UsDMXdrJC"
      },
      "outputs": [],
      "source": [
        "tokens, pos = get_vocabulary(\"/content/drive/MyDrive/eng-ner-dataset/engIOB2.train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cys0c0Sn7GI2",
        "outputId": "4c992d29-29e7-4eda-b8bd-75fd855110dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46\n"
          ]
        }
      ],
      "source": [
        "print(len(pos.keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LorsrI9-uqL"
      },
      "source": [
        "## Feature Selection and Data Frames\n",
        "\n",
        "The most important question to ask at this point is about the features. *What are the type of features likely to be important in the identification of various kinds of named entities?*\n",
        "\n",
        "Unsurprisingly, the token itself and its part of speech are the most important indicators. For example, a conjunction is probably not the name of a person; an adjective is probably not a part of the name of a place (assuming that the greatness of \"Great Britain\" or the length of \"Long Island\" are correctly tagged as nouns). A few other features that research in NER detection has found to be helpful are the orthographic properties of a token, which involve the patterns of capitalization (e.g., is the word in all capital letters? is it starting with a capital letter?), the POS tags of surroundings tokens, the surrounding tokens themselves, and the orthographic properties of the surrounding tokens.\n",
        "\n",
        "You are by no means restricted to use only these properties. They are provided to you as a minimal set to explore (i.e., a starting point from where you can/should explore incorporating better features).\n",
        "\n",
        "This work is what people often call **feature engineering**. It is, in some ways, \"old school\" NLP. Nevertheless, it is a relatively recent phase of NLP research, and going through this help you gain hands-on knowledge of various programming tools/approaches in NLP. It will (hopefully) also help you appreciate the complexity and utility of neural networks where such feature engineering is rarely needed.\n",
        "\n",
        "It is, of course, important to represent the training, development, and test instances using the same set of features. And for the supervised classification, we want to store the training, development, and test sets are data frames (essentially, vectors with class labels). Your next task is to complete the following method to do this.\n",
        "\n",
        "First, let's define an enumerable type so that only a fixed set of the \"kinds of data frames\" are allowed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDZIReiIDTIE"
      },
      "outputs": [],
      "source": [
        "from enum import Enum\n",
        "\n",
        "class ActionType(Enum):\n",
        "    TRAIN = 'train'\n",
        "    TEST = 'test'\n",
        "    DEV = 'dev'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mySxjuyDs-X"
      },
      "source": [
        "Use this `ActionType` below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7qZnJadD4d5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "def create_dataframe(actiontype: ActionType, output_file_name: str) -> None:\n",
        "    \"\"\"\n",
        "    Generate a pandas DataFrame from text files containing sentences (tokenized and annotated, in IOB or IOB2 format)\n",
        "    and class labels, and write the DataFrame to a CSV file.\n",
        "\n",
        "    Parameters:\n",
        "        actiontype (ActionType): The type of action, either ActionType.TRAIN, ActionType.TEST, or ActionType.DEV.\n",
        "        output_file_name (str): The name of the output CSV file.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: If the input training or test file is not found.\n",
        "    \"\"\"\n",
        "    if actiontype == ActionType.TRAIN:\n",
        "        input_file = '/content/drive/MyDrive/eng-ner-dataset/engIOB2.train'\n",
        "    elif actiontype == ActionType.TEST:\n",
        "        input_file = '/content/drive/MyDrive/eng-ner-dataset/engIOB2.testb'\n",
        "    elif actiontype == ActionType.DEV:\n",
        "        input_file = '/content/drive/MyDrive/eng-ner-dataset/engIOB2.testa'\n",
        "    else:\n",
        "        raise ValueError(\"Invalid action type\")\n",
        "\n",
        "    try:\n",
        "        with open(input_file, 'r') as file:\n",
        "            data = []\n",
        "            sentences = file.read().strip().split('\\n\\n')\n",
        "            for sentence in sentences:\n",
        "                lines = sentence.split('\\n')\n",
        "                tokens = lines[::4]\n",
        "                pos_tags = lines[1::4]\n",
        "                labels = lines[3::4]\n",
        "                for i, (token, pos, label) in enumerate(zip(tokens, pos_tags, labels)):\n",
        "                    features = {\n",
        "                        'POS': pos,\n",
        "                        'PrevLabel': labels[i-1] if i > 0 else '',\n",
        "                        'NextLabel': labels[i+1] if i < len(labels)-1 else '',\n",
        "\n",
        "                        'PrevIsAllCaps': (1 if tokens[i-1].isupper() else 0) if i > 0 else 0,\n",
        "                        'IsAllCaps': 1 if token.isupper() else 0,\n",
        "                        'NextIsAllCaps': (1 if tokens[i+1].isupper() else 0) if i < len(tokens)-1 else 0,\n",
        "\n",
        "                        'PrevIsTitle': (1 if tokens[i-1].istitle() else 0) if i > 0 else 0,\n",
        "                        'IsTitle': 1 if token.istitle() else 0,\n",
        "                        'NextIsTitle': (1 if tokens[i+1].istitle() else 0) if i < len(tokens)-1 else 0,\n",
        "\n",
        "                        'PrevHasDigits': (1 if any(char.isdigit() for char in tokens[i-1]) else 0) if i > 0 else 0,\n",
        "                        'HasDigits': 1 if any(char.isdigit() for char in token) else 0,\n",
        "                        'NextHasDigits': (1 if any(char.isdigit() for char in tokens[i+1]) else 0) if i < len(tokens)-1 else 0,\n",
        "\n",
        "                        'PrevHasPunctuations': (1 if any(char in '.,;?!' for char in tokens[i-1]) else 0) if i > 0 else 0,\n",
        "                        'HasPunctuations': 1 if any(char in '.,;?!' for char in token) else 0,\n",
        "                        'NextHasPunctuations': (1 if any(char in '.,;?!' for char in tokens[i+1]) else 0) if i < len(tokens)-1 else 0,\n",
        "\n",
        "                        'TokenLength': len(token),\n",
        "                        'Label': label\n",
        "                    }\n",
        "                    data.append(features)\n",
        "          # Create the DataFrame from the collected data\n",
        "        df = pd.DataFrame(data)\n",
        "\n",
        "        df[\"POS\"] = pd.Categorical(df[\"POS\"], categories=['NNP', 'VBZ', 'JJ', 'NN', 'TO', 'VB', '.', 'CD', 'DT', 'VBD', 'IN', 'PRP', 'NNS', 'VBP', 'MD', 'VBN', 'POS', 'JJR', '\"', 'RB', ',', 'FW', 'CC', 'WDT', '(', ')', ':', 'PRP$', 'RBR', 'VBG', 'EX', 'WP', 'WRB', '-X-', '$', 'RP', 'NNPS', 'SYM', 'RBS', 'UH', 'PDT', \"''\", 'LS', 'JJS', 'WP$', 'NN|SYM'])\n",
        "        df['PrevLabel'] = pd.Categorical(df['PrevLabel'], categories=['B-ORG', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER', 'O', 'B-MISC'])\n",
        "        df['NextLabel'] = pd.Categorical(df['NextLabel'], categories=['B-ORG', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER', 'O', 'B-MISC'])\n",
        "\n",
        "        # One-hot encode the 'POS', 'NextLabel', and 'PrevLabel' columns\n",
        "        pos_dummies = pd.get_dummies(df['POS'], prefix='POS')\n",
        "        next_label_dummies = pd.get_dummies(df['NextLabel'], prefix='NextLabel')\n",
        "        prev_label_dummies = pd.get_dummies(df['PrevLabel'], prefix='PrevLabel')\n",
        "\n",
        "        # Concatenate the one-hot encoded columns with the original DataFrame\n",
        "        df = pd.concat([df, pos_dummies, next_label_dummies, prev_label_dummies], axis=1)\n",
        "\n",
        "        # Optionally, you can drop the original columns if you don't need them anymore\n",
        "        df = df.drop(['POS', 'NextLabel', 'PrevLabel'], axis=1)\n",
        "\n",
        "        # Write the DataFrame to a CSV file\n",
        "        df.to_csv(output_file_name, index=False)\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f\"The file {input_file} does not exist\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "SjtqisA_JwzX",
        "outputId": "aa5a2b99-fc4e-49d6-f28c-aa58afee77f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        PrevIsAllCaps  IsAllCaps  NextIsAllCaps  PrevIsTitle  IsTitle  \\\n",
              "0                   0          1              0            0        0   \n",
              "1                   1          0              0            0        0   \n",
              "2                   0          0              0            0        1   \n",
              "3                   0          0              0            1        0   \n",
              "4                   0          0              0            0        0   \n",
              "...               ...        ...            ...          ...      ...   \n",
              "204562              0          0              0            0        1   \n",
              "204563              0          0              0            1        0   \n",
              "204564              0          0              0            0        1   \n",
              "204565              0          0              0            1        0   \n",
              "204566              0          1              0            0        0   \n",
              "\n",
              "        NextIsTitle  PrevHasDigits  HasDigits  NextHasDigits  \\\n",
              "0                 0              0          0              0   \n",
              "1                 1              0          0              0   \n",
              "2                 0              0          0              0   \n",
              "3                 0              0          0              0   \n",
              "4                 0              0          0              0   \n",
              "...             ...            ...        ...            ...   \n",
              "204562            0              0          0              1   \n",
              "204563            1              0          1              0   \n",
              "204564            0              1          0              1   \n",
              "204565            0              0          1              0   \n",
              "204566            0              0          0              0   \n",
              "\n",
              "        PrevHasPunctuations  ...  NextLabel_I-PER  NextLabel_O  \\\n",
              "0                         0  ...                0            1   \n",
              "1                         0  ...                0            0   \n",
              "2                         0  ...                0            1   \n",
              "3                         0  ...                0            1   \n",
              "4                         0  ...                0            1   \n",
              "...                     ...  ...              ...          ...   \n",
              "204562                    0  ...                0            1   \n",
              "204563                    0  ...                0            0   \n",
              "204564                    0  ...                0            1   \n",
              "204565                    0  ...                0            0   \n",
              "204566                    0  ...                0            0   \n",
              "\n",
              "        NextLabel_B-MISC PrevLabel_B-ORG  PrevLabel_I-LOC  PrevLabel_I-MISC  \\\n",
              "0                      0               0                0                 0   \n",
              "1                      0               0                0                 0   \n",
              "2                      0               0                0                 0   \n",
              "3                      0               0                0                 1   \n",
              "4                      0               0                0                 0   \n",
              "...                  ...             ...              ...               ...   \n",
              "204562                 0               0                0                 0   \n",
              "204563                 0               0                0                 0   \n",
              "204564                 0               0                0                 0   \n",
              "204565                 0               0                0                 0   \n",
              "204566                 0               0                0                 0   \n",
              "\n",
              "        PrevLabel_I-ORG  PrevLabel_I-PER  PrevLabel_O  PrevLabel_B-MISC  \n",
              "0                     0                0            0                 0  \n",
              "1                     1                0            0                 0  \n",
              "2                     0                0            1                 0  \n",
              "3                     0                0            0                 0  \n",
              "4                     0                0            1                 0  \n",
              "...                 ...              ...          ...               ...  \n",
              "204562                0                0            0                 0  \n",
              "204563                1                0            0                 0  \n",
              "204564                0                0            1                 0  \n",
              "204565                1                0            0                 0  \n",
              "204566                0                0            0                 0  \n",
              "\n",
              "[204567 rows x 74 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a41d1384-6798-4054-9922-38894f040f1f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PrevIsAllCaps</th>\n",
              "      <th>IsAllCaps</th>\n",
              "      <th>NextIsAllCaps</th>\n",
              "      <th>PrevIsTitle</th>\n",
              "      <th>IsTitle</th>\n",
              "      <th>NextIsTitle</th>\n",
              "      <th>PrevHasDigits</th>\n",
              "      <th>HasDigits</th>\n",
              "      <th>NextHasDigits</th>\n",
              "      <th>PrevHasPunctuations</th>\n",
              "      <th>...</th>\n",
              "      <th>NextLabel_I-PER</th>\n",
              "      <th>NextLabel_O</th>\n",
              "      <th>NextLabel_B-MISC</th>\n",
              "      <th>PrevLabel_B-ORG</th>\n",
              "      <th>PrevLabel_I-LOC</th>\n",
              "      <th>PrevLabel_I-MISC</th>\n",
              "      <th>PrevLabel_I-ORG</th>\n",
              "      <th>PrevLabel_I-PER</th>\n",
              "      <th>PrevLabel_O</th>\n",
              "      <th>PrevLabel_B-MISC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204562</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204563</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204564</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204565</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204566</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>204567 rows Ã— 74 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a41d1384-6798-4054-9922-38894f040f1f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a41d1384-6798-4054-9922-38894f040f1f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a41d1384-6798-4054-9922-38894f040f1f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5ca1b602-17e0-4858-b33f-d5ff2466409e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5ca1b602-17e0-4858-b33f-d5ff2466409e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5ca1b602-17e0-4858-b33f-d5ff2466409e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "create_dataframe(ActionType.TRAIN, \"training.csv\")\n",
        "pandas.read_csv(\"training.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "fzujOdo2ThwV",
        "outputId": "def722fb-3e49-41c5-f331-70555b0de5df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       PrevIsAllCaps  IsAllCaps  NextIsAllCaps  PrevIsTitle  IsTitle  \\\n",
              "0                  0          1              0            0        0   \n",
              "1                  1          0              1            0        0   \n",
              "2                  0          1              1            0        0   \n",
              "3                  1          1              1            0        0   \n",
              "4                  1          1              1            0        0   \n",
              "...              ...        ...            ...          ...      ...   \n",
              "51573              0          0              0            0        0   \n",
              "51574              0          0              0            0        1   \n",
              "51575              0          0              0            1        1   \n",
              "51576              0          0              0            1        0   \n",
              "51577              0          1              0            0        0   \n",
              "\n",
              "       NextIsTitle  PrevHasDigits  HasDigits  NextHasDigits  \\\n",
              "0                0              0          0              0   \n",
              "1                0              0          0              0   \n",
              "2                0              0          0              0   \n",
              "3                0              0          0              0   \n",
              "4                0              0          0              0   \n",
              "...            ...            ...        ...            ...   \n",
              "51573            1              0          0              0   \n",
              "51574            1              0          0              0   \n",
              "51575            0              0          0              1   \n",
              "51576            0              0          1              0   \n",
              "51577            0              0          0              0   \n",
              "\n",
              "       PrevHasPunctuations  ...  NextLabel_I-PER  NextLabel_O  \\\n",
              "0                        0  ...                0            1   \n",
              "1                        0  ...                0            0   \n",
              "2                        0  ...                0            1   \n",
              "3                        0  ...                0            1   \n",
              "4                        0  ...                0            1   \n",
              "...                    ...  ...              ...          ...   \n",
              "51573                    0  ...                0            0   \n",
              "51574                    0  ...                0            0   \n",
              "51575                    0  ...                0            1   \n",
              "51576                    0  ...                0            0   \n",
              "51577                    0  ...                0            0   \n",
              "\n",
              "       NextLabel_B-MISC PrevLabel_B-ORG  PrevLabel_I-LOC  PrevLabel_I-MISC  \\\n",
              "0                     0               0                0                 0   \n",
              "1                     0               0                0                 0   \n",
              "2                     0               0                0                 0   \n",
              "3                     0               0                0                 0   \n",
              "4                     0               0                0                 0   \n",
              "...                 ...             ...              ...               ...   \n",
              "51573                 0               0                0                 0   \n",
              "51574                 0               0                0                 0   \n",
              "51575                 0               0                0                 0   \n",
              "51576                 0               0                0                 0   \n",
              "51577                 0               0                0                 0   \n",
              "\n",
              "       PrevLabel_I-ORG  PrevLabel_I-PER  PrevLabel_O  PrevLabel_B-MISC  \n",
              "0                    0                0            0                 0  \n",
              "1                    0                0            1                 0  \n",
              "2                    0                0            1                 0  \n",
              "3                    1                0            0                 0  \n",
              "4                    0                0            1                 0  \n",
              "...                ...              ...          ...               ...  \n",
              "51573                0                0            0                 0  \n",
              "51574                0                0            1                 0  \n",
              "51575                1                0            0                 0  \n",
              "51576                1                0            0                 0  \n",
              "51577                0                0            0                 0  \n",
              "\n",
              "[51578 rows x 74 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-204eeafd-06e0-45bf-a27a-2a7dd9d30a24\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PrevIsAllCaps</th>\n",
              "      <th>IsAllCaps</th>\n",
              "      <th>NextIsAllCaps</th>\n",
              "      <th>PrevIsTitle</th>\n",
              "      <th>IsTitle</th>\n",
              "      <th>NextIsTitle</th>\n",
              "      <th>PrevHasDigits</th>\n",
              "      <th>HasDigits</th>\n",
              "      <th>NextHasDigits</th>\n",
              "      <th>PrevHasPunctuations</th>\n",
              "      <th>...</th>\n",
              "      <th>NextLabel_I-PER</th>\n",
              "      <th>NextLabel_O</th>\n",
              "      <th>NextLabel_B-MISC</th>\n",
              "      <th>PrevLabel_B-ORG</th>\n",
              "      <th>PrevLabel_I-LOC</th>\n",
              "      <th>PrevLabel_I-MISC</th>\n",
              "      <th>PrevLabel_I-ORG</th>\n",
              "      <th>PrevLabel_I-PER</th>\n",
              "      <th>PrevLabel_O</th>\n",
              "      <th>PrevLabel_B-MISC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51573</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51574</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51575</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51576</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51577</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>51578 rows Ã— 74 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-204eeafd-06e0-45bf-a27a-2a7dd9d30a24')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-204eeafd-06e0-45bf-a27a-2a7dd9d30a24 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-204eeafd-06e0-45bf-a27a-2a7dd9d30a24');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-033f762d-04e9-49ca-8106-c2cbfd5842da\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-033f762d-04e9-49ca-8106-c2cbfd5842da')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-033f762d-04e9-49ca-8106-c2cbfd5842da button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "create_dataframe(ActionType.DEV, \"testing.csv\")\n",
        "pandas.read_csv(\"testing.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "create_dataframe(ActionType.TEST, \"testingB.csv\")\n",
        "pandas.read_csv(\"testingB.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "gbxlzbYnXddm",
        "outputId": "4eda369e-c70b-4180-d92f-e1efd4e37e5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       PrevIsAllCaps  IsAllCaps  NextIsAllCaps  PrevIsTitle  IsTitle  \\\n",
              "0                  0          1              0            0        0   \n",
              "1                  1          0              1            0        0   \n",
              "2                  0          1              1            0        0   \n",
              "3                  1          1              1            0        0   \n",
              "4                  1          1              1            0        0   \n",
              "...              ...        ...            ...          ...      ...   \n",
              "46661              0          0              0            0        0   \n",
              "46662              0          0              0            0        0   \n",
              "46663              0          0              0            0        1   \n",
              "46664              0          0              0            1        0   \n",
              "46665              0          1              0            0        0   \n",
              "\n",
              "       NextIsTitle  PrevHasDigits  HasDigits  NextHasDigits  \\\n",
              "0                0              0          0              0   \n",
              "1                0              0          0              0   \n",
              "2                0              0          0              0   \n",
              "3                0              0          0              0   \n",
              "4                0              0          0              0   \n",
              "...            ...            ...        ...            ...   \n",
              "46661            0              0          0              0   \n",
              "46662            1              0          0              0   \n",
              "46663            0              0          0              0   \n",
              "46664            0              0          0              0   \n",
              "46665            0              0          0              0   \n",
              "\n",
              "       PrevHasPunctuations  ...  NextLabel_I-PER  NextLabel_O  \\\n",
              "0                        0  ...                0            1   \n",
              "1                        0  ...                0            0   \n",
              "2                        0  ...                0            1   \n",
              "3                        0  ...                0            1   \n",
              "4                        0  ...                0            1   \n",
              "...                    ...  ...              ...          ...   \n",
              "46661                    0  ...                0            1   \n",
              "46662                    0  ...                1            0   \n",
              "46663                    1  ...                0            1   \n",
              "46664                    0  ...                0            0   \n",
              "46665                    0  ...                0            0   \n",
              "\n",
              "       NextLabel_B-MISC PrevLabel_B-ORG  PrevLabel_I-LOC  PrevLabel_I-MISC  \\\n",
              "0                     0               0                0                 0   \n",
              "1                     0               0                0                 0   \n",
              "2                     0               0                0                 0   \n",
              "3                     0               0                1                 0   \n",
              "4                     0               0                0                 0   \n",
              "...                 ...             ...              ...               ...   \n",
              "46661                 0               0                0                 0   \n",
              "46662                 0               0                0                 0   \n",
              "46663                 0               0                0                 0   \n",
              "46664                 0               0                0                 0   \n",
              "46665                 0               0                0                 0   \n",
              "\n",
              "       PrevLabel_I-ORG  PrevLabel_I-PER  PrevLabel_O  PrevLabel_B-MISC  \n",
              "0                    0                0            0                 0  \n",
              "1                    0                0            1                 0  \n",
              "2                    0                0            1                 0  \n",
              "3                    0                0            0                 0  \n",
              "4                    0                0            1                 0  \n",
              "...                ...              ...          ...               ...  \n",
              "46661                0                0            1                 0  \n",
              "46662                0                0            1                 0  \n",
              "46663                0                0            1                 0  \n",
              "46664                0                1            0                 0  \n",
              "46665                0                0            0                 0  \n",
              "\n",
              "[46666 rows x 74 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-286b3587-e14d-44cd-8ce0-5251c12e28af\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PrevIsAllCaps</th>\n",
              "      <th>IsAllCaps</th>\n",
              "      <th>NextIsAllCaps</th>\n",
              "      <th>PrevIsTitle</th>\n",
              "      <th>IsTitle</th>\n",
              "      <th>NextIsTitle</th>\n",
              "      <th>PrevHasDigits</th>\n",
              "      <th>HasDigits</th>\n",
              "      <th>NextHasDigits</th>\n",
              "      <th>PrevHasPunctuations</th>\n",
              "      <th>...</th>\n",
              "      <th>NextLabel_I-PER</th>\n",
              "      <th>NextLabel_O</th>\n",
              "      <th>NextLabel_B-MISC</th>\n",
              "      <th>PrevLabel_B-ORG</th>\n",
              "      <th>PrevLabel_I-LOC</th>\n",
              "      <th>PrevLabel_I-MISC</th>\n",
              "      <th>PrevLabel_I-ORG</th>\n",
              "      <th>PrevLabel_I-PER</th>\n",
              "      <th>PrevLabel_O</th>\n",
              "      <th>PrevLabel_B-MISC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46661</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46662</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46663</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46664</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46665</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>46666 rows Ã— 74 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-286b3587-e14d-44cd-8ce0-5251c12e28af')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-286b3587-e14d-44cd-8ce0-5251c12e28af button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-286b3587-e14d-44cd-8ce0-5251c12e28af');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a35deea9-4c72-4ff9-810c-9810e178fdae\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a35deea9-4c72-4ff9-810c-9810e178fdae')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a35deea9-4c72-4ff9-810c-9810e178fdae button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rS97gcIxT2QD",
        "outputId": "38b7925e-1251-493f-c41a-7bb3e04bfceb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set()"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "set1 = set(pandas.read_csv(\"testing.csv\").columns)\n",
        "set2 = set(pandas.read_csv(\"training.csv\").columns)\n",
        "set3 = set(pandas.read_csv(\"testingB.csv\").columns)\n",
        "set1-set3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGTTAEMYFwwd"
      },
      "source": [
        "# Binary Logistic Regression Classifier [30 points]\n",
        "\n",
        "Now that your data frames are built, it is time to build your binary logistic regression classifier to identify if a token is a part of a person's name. To do this, you can effectively treat the labels `I-PER` and `B-PER` together as a single label, `PER`, and treat all the other labels simply as *other*, denoted by `O` (how you denote it internally in your code is entirely up to you).\n",
        "\n",
        "Complete the class `BinaryLogisticRegression` below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_DOlmsKbus6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "from sklearn.metrics import log_loss\n",
        "import ast\n",
        "\n",
        "class LogisticRegressionClassifier:\n",
        "    \"\"\"\n",
        "    A binary logistic regression classifier.\n",
        "\n",
        "    Attributes:\n",
        "        learning_rate (float): The learning rate for gradient descent.\n",
        "        learning_rate_decay (float, optional): The factor by which learning rate decays with each iteration.\n",
        "        num_iterations (int): The number of iterations for gradient descent.\n",
        "        weights (ndarray): The weights for the features.\n",
        "        bias (float): The bias term.\n",
        "        training_data (pandas.DataFrame): The training data as a pandas DataFrame (to be read from a valid CSV file)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, training_data_csv: str, learning_rate=0.01, learning_rate_decay=1.0, num_iterations=1000,\n",
        "                 regularization='l2', regularization_strength=0.1, threshold=0.5):\n",
        "        self.training_data_csv = training_data_csv\n",
        "        self.learning_rate = learning_rate\n",
        "        self.learning_rate_decay = learning_rate_decay\n",
        "        self.num_iterations = num_iterations\n",
        "        self.regularization = regularization\n",
        "        self.regularization_strength = regularization_strength\n",
        "        self.threshold = threshold\n",
        "        self.df = pd.read_csv(training_data_csv)\n",
        "        self.weights = np.zeros(self.__to_feature_matrix(self.df).shape[1])\n",
        "        self.bias = 0\n",
        "\n",
        "    @staticmethod\n",
        "    def sigmoid(z: float) -> float:\n",
        "        \"\"\"\n",
        "        Compute the sigmoid function.\n",
        "\n",
        "        Parameters:\n",
        "            z (float): The input to the sigmoid function.\n",
        "\n",
        "        Returns:\n",
        "            float: The output of the sigmoid function.\n",
        "        \"\"\"\n",
        "        return 1 / (1 + numpy.exp(-z))\n",
        "\n",
        "    def __to_feature_matrix(self, df: pandas.DataFrame) -> pandas.DataFrame:\n",
        "        \"\"\"\n",
        "        A private method to extract the feature matrix from the data frame.\n",
        "\n",
        "        Parameters:\n",
        "            df (pandas.DataFrame): The given data frame.\n",
        "\n",
        "        Returns:\n",
        "            The matrix of features as a pandas DataFrame\n",
        "        \"\"\"\n",
        "        # TODO\n",
        "        return df.drop('Label', axis='columns')\n",
        "    def __to_class_labels(self, df: pandas.DataFrame) -> pandas.DataFrame:\n",
        "        \"\"\"\n",
        "        A private method to extract the class labels from the data frame.\n",
        "\n",
        "        Parameters:\n",
        "            df (pandas.DataFrame): The given data frame.\n",
        "\n",
        "        Returns:\n",
        "            The vector of class labels as a pandas DataFrame.\n",
        "        \"\"\"\n",
        "        # TODO\n",
        "        df['Label'] = df['Label'].apply(lambda x: 1 if x in ['I-PER', 'B-PER'] else 0)\n",
        "        return df['Label']\n",
        "\n",
        "\n",
        "    def learn(self, X, y, batch_size=250):\n",
        "        \"\"\"\n",
        "        Learn the weight vector to obtain the best decision boundary that separates the two classes in the training set.\n",
        "\n",
        "        It initializes the model parameters (the weights are initialized to zeros, and the bias is also initially set to\n",
        "        zero). It then performs gradient descent to optimize the parameters based on the training data. The optimization\n",
        "        is done by minimizing the cross-entropy loss or the logistic loss. The learning rate determines the step size\n",
        "        taken during gradient descent. If the decay factor is less than 1, the step size reduces with each iteration.\n",
        "\n",
        "        Parameters:\n",
        "            feature_matrix (ndarray): The feature matrix.\n",
        "            y (ndarray): The target class labels.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        # TODO\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            X = X.to_numpy()\n",
        "\n",
        "        self.weights = np.zeros(X.shape[1])\n",
        "        self.bias = 0\n",
        "        update_interval = self.num_iterations // 10\n",
        "\n",
        "        for i in range(self.num_iterations):\n",
        "            if update_interval and (i % update_interval == 0):\n",
        "                print(f\"Iteration {i} - {int((i / self.num_iterations) * 100)}% complete.\")\n",
        "\n",
        "            # Shuffle the dataset\n",
        "            indices = np.random.permutation(len(X))\n",
        "            X_shuffled = X[indices]\n",
        "            y_shuffled = y[indices]\n",
        "\n",
        "            for start in range(0, len(X), batch_size):\n",
        "                end = start + batch_size\n",
        "                X_batch = X_shuffled[start:end]\n",
        "                y_batch = y_shuffled[start:end]\n",
        "\n",
        "                # Skip empty batches\n",
        "                if X_batch.size == 0:\n",
        "                    continue\n",
        "\n",
        "                predictions = self.sigmoid(np.dot(X_batch, self.weights) + self.bias)\n",
        "                errors = predictions - y_batch\n",
        "\n",
        "                # Compute gradients for weights and bias\n",
        "                gradient_weights = np.dot(X_batch.T, errors) / len(X_batch)\n",
        "                gradient_bias = np.mean(errors)\n",
        "\n",
        "                # Apply L2 regularization\n",
        "                if self.regularization == 'l2':\n",
        "                    gradient_weights += (self.regularization_strength / len(X_batch)) * self.weights\n",
        "\n",
        "                # Apply L1 regularization\n",
        "                elif self.regularization == 'l1':\n",
        "                    gradient_weights += (self.regularization_strength / len(X_batch)) * np.sign(self.weights)\n",
        "\n",
        "                # Update weights and bias\n",
        "                self.weights -= self.learning_rate * gradient_weights\n",
        "                self.bias -= self.learning_rate * gradient_bias\n",
        "\n",
        "\n",
        "    def predict(self, feature_matrix) -> List[int]:\n",
        "        \"\"\"\n",
        "        Predict the target labels for new/test data.\n",
        "\n",
        "        Parameters:\n",
        "            feature_matrix (ndarray): The feature matrix of new/test data.\n",
        "\n",
        "        Returns:\n",
        "            list: The predicted target labels.\n",
        "        \"\"\"\n",
        "        # TODO\n",
        "        return (self.sigmoid(np.dot(feature_matrix, self.weights) + self.bias) >= self.threshold).astype(int)\n",
        "\n",
        "    def set_threshold(self, threshold: float):\n",
        "        \"\"\"\n",
        "        Set a new threshold value for the classifier.\n",
        "\n",
        "        Parameters:\n",
        "            threshold (float): The new threshold value.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def compute_loss(self, feature_matrix, y_true):\n",
        "        \"\"\"\n",
        "        Compute the binary cross-entropy loss.\n",
        "\n",
        "        Parameters:\n",
        "            feature_matrix (ndarray): The feature matrix of new/test data.\n",
        "            y_true (ndarray): The true class labels.\n",
        "\n",
        "        Returns:\n",
        "            float: The binary cross-entropy loss.\n",
        "        \"\"\"\n",
        "        predictions = self.sigmoid(np.dot(feature_matrix, self.weights) + self.bias)\n",
        "        return log_loss(y_true, predictions)\n",
        "\n",
        "    def report(self, feature_matrix: numpy.ndarray, y_true: numpy.ndarray) -> Tuple[float, float, float]:\n",
        "        \"\"\"\n",
        "        Compute the precision, recall, and F-1 scores for new/test data.\n",
        "\n",
        "        Parameters:\n",
        "            feature_matrix (ndarray): The feature matrix of new/test data.\n",
        "            y_true (ndarray): The true class labels.\n",
        "\n",
        "        Returns:\n",
        "            Tuple[float, float, float]: A tuple containing three values: the positive class' precision, recall, and F-1\n",
        "            scores (in this order)\n",
        "        \"\"\"\n",
        "        # TODO\n",
        "        #\n",
        "        # Note 1: For binary classification, we only need these three values for the positive class (instead of micro-\n",
        "        # or macro-averaging). The PER class is considered as the positive class for this component of the assignment.\n",
        "        #\n",
        "        # Note 2: You should aim for an F-1 measure of at least 0.7 on the final test set (eng.testb)\n",
        "        y_pred = self.predict(feature_matrix)\n",
        "        precision = precision_score(y_true, y_pred)\n",
        "        recall = recall_score(y_true, y_pred)\n",
        "        f1 = f1_score(y_true, y_pred)\n",
        "        return precision, recall, f1\n",
        "\n",
        "    def printWB(self):\n",
        "        print(f\"W: {self.weights} and B: {self.bias}\")\n",
        "\n",
        "    def predict_proba(self, feature_matrix):\n",
        "        return self.sigmoid(np.dot(feature_matrix, self.weights) + self.bias)\n",
        "\n",
        "    # Public method that calls the private method\n",
        "    def get_feature_matrix(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        return self.__to_feature_matrix(df)\n",
        "\n",
        "    # Public method that calls the private method\n",
        "    def get_class_labels(self, df: pd.DataFrame) -> pd.Series:\n",
        "        return self.__to_class_labels(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqiddgYNHCmf"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tv2lzZDEd5q0",
        "outputId": "32cea972-52e4-42ad-bd26-001d6f59c49f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0 - 0% complete.\n",
            "Iteration 100 - 10% complete.\n",
            "Iteration 200 - 20% complete.\n",
            "Iteration 300 - 30% complete.\n",
            "Iteration 400 - 40% complete.\n",
            "Iteration 500 - 50% complete.\n",
            "Iteration 600 - 60% complete.\n",
            "Iteration 700 - 70% complete.\n",
            "Iteration 800 - 80% complete.\n",
            "Iteration 900 - 90% complete.\n",
            "Precision: 0.9484841827768014, Recall: 0.7759705248023006, F1 Score: 0.8535982601818901\n"
          ]
        }
      ],
      "source": [
        "classifier = LogisticRegressionClassifier('training.csv')\n",
        "classifier.set_threshold(0.5)\n",
        "\n",
        "train_data = classifier.df\n",
        "train_feature_matrix = classifier.get_feature_matrix(train_data)\n",
        "train_labels = classifier.get_class_labels(train_data)\n",
        "\n",
        "classifier.learn(train_feature_matrix, train_labels)\n",
        "\n",
        "precision, recall, f1 = classifier.report(train_feature_matrix, train_labels)\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uKvBy8rHGe8"
      },
      "source": [
        "## Calculating Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTmz6aI9789v",
        "outputId": "db9d7c61-0eac-46c3-a2b1-37685b9752f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary Cross-Entropy Loss: 0.05030440624329137\n"
          ]
        }
      ],
      "source": [
        "loss = classifier.compute_loss(train_feature_matrix, train_labels)\n",
        "print(f\"Binary Cross-Entropy Loss: {loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7Z_zBG2HJm9"
      },
      "source": [
        "## Testing the model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing on dev set"
      ],
      "metadata": {
        "id": "f99dc1EIcBqH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTM6iDdzxP7n",
        "outputId": "978e17aa-1891-4e42-962f-00a2deec8b7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.960967993754879, Recall: 0.7818355033343919, F1 Score: 0.862195762563474\n"
          ]
        }
      ],
      "source": [
        "test_data = test_data = pd.read_csv('testing.csv')\n",
        "\n",
        "test_feature_matrix = classifier.get_feature_matrix(test_data)\n",
        "test_labels = classifier.get_class_labels(test_data)\n",
        "\n",
        "precision, recall, f1 = classifier.report(test_feature_matrix, test_labels)\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing on test set"
      ],
      "metadata": {
        "id": "cB_WdrsUcF8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = test_data = pd.read_csv('testingB.csv')\n",
        "\n",
        "test_feature_matrix = classifier.get_feature_matrix(test_data)\n",
        "test_labels = classifier.get_class_labels(test_data)\n",
        "\n",
        "precision, recall, f1 = classifier.report(test_feature_matrix, test_labels)\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFhtJT_ab6Rv",
        "outputId": "c631e0c3-6367-40d9-faac-18e86b34bde3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9471195184866724, Recall: 0.7944464478903714, F1 Score: 0.8640909982349481\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4-t3y1rRAi_"
      },
      "source": [
        "# Multinomial Logistic Regression Classifier [30 points]\n",
        "\n",
        "This is also known as **Softmax Regression** or **Maxent Classifier**. It is a popular tool for multi-class classification, which we will use here for NER.\n",
        "\n",
        "Note that the classification is happening on a *per-token* basis, and the class labels are `B-ORG`, `I-ORG`, etc.\n",
        "\n",
        "Generalizing the binary classification task, you should complete the `MultinomialLogisticRegression` class, whose skeleton is provided to you next. For this portion, you may (optionally) import the `OneHotEncoder` or `LabelEncoder` from scikit-learn. For example, you may add this line at the beginning of the next cell:\n",
        "\n",
        "```\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOZznbUPWkv3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "\n",
        "class MultinomialLogisticRegression:\n",
        "    \"\"\"\n",
        "    A multinomial logistic regression classifier.\n",
        "\n",
        "    Attributes:\n",
        "        learning_rate (float): The learning rate for gradient descent.\n",
        "        learning_rate_decay (float): The factor by which learning rate decays with each iteration.\n",
        "        weights (ndarray): The weights for the features.\n",
        "        bias (float): The bias term.\n",
        "        training_data (pandas.DataFrame): The training data as a pandas DataFrame (to be read from a valid CSV file)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, learning_rate: float, learning_rate_decay: float, epochs: int, training_data_csv: str):\n",
        "        \"\"\"\n",
        "        Initialize the multinomial logistic regression classifier.\n",
        "\n",
        "        Parameters:\n",
        "            learning_rate (float): The learning rate for gradient descent.\n",
        "            learning_rate_decay (float): The factor by which learning rate decays with each iteration.\n",
        "            epochs (int): The number of training epochs.\n",
        "            training_data_csv (str): The file path to the CSV file containing training data.\n",
        "        \"\"\"\n",
        "        # TODO\n",
        "        self.learning_rate = learning_rate\n",
        "        self.learning_rate_decay = learning_rate_decay\n",
        "        self.epochs = epochs\n",
        "        self.training_data_csv = training_data_csv\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "        self.label_encoder = None\n",
        "        self.initialize(training_data_csv)\n",
        "\n",
        "    @staticmethod\n",
        "    def softmax(logits):\n",
        "        \"\"\"\n",
        "        Compute the softmax function.\n",
        "\n",
        "        Parameters:\n",
        "            z (numpy.ndarray): The input to the softmax function.\n",
        "\n",
        "        Returns:\n",
        "            numpy.ndarray: The output of the softmax function.\n",
        "        \"\"\"\n",
        "        exp_logits = numpy.exp(logits - numpy.max(logits))\n",
        "        return exp_logits / numpy.sum(exp_logits)\n",
        "\n",
        "    def learn(self) -> None:\n",
        "        \"\"\"\n",
        "        Train the multinomial logistic regression model.\n",
        "\n",
        "        This method trains the multinomial logistic regression model using stochastic gradient descent. It begins by\n",
        "        encoding the target labels into one-hot encoded vectors and initializes the weights (to zeros) for the model.\n",
        "        During each training epoch, it iterates through the training data, computing the softmax probabilities for each\n",
        "        class and updating the weights based on the gradient of the cross-entropy loss.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        # TODO\n",
        "        # Note: Remember to use regularization, but think about what type of regularization might suit this task.\n",
        "        onehot_encoder = OneHotEncoder(sparse=False)\n",
        "        y = self.training_data['Label'].values.reshape(-1, 1)\n",
        "        y_onehot = onehot_encoder.fit_transform(y)\n",
        "        X = self.training_data.drop('Label', axis=1).values\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            logits = np.dot(X, self.weights.T) + self.bias\n",
        "            probs = self.softmax(logits)\n",
        "\n",
        "            # Compute the gradient of the cross-entropy loss\n",
        "            error = probs - y_onehot\n",
        "            gradient_weights = np.dot(error.T, X) / X.shape[0]\n",
        "            gradient_bias = np.mean(error, axis=0)\n",
        "\n",
        "            # Update weights and bias\n",
        "            self.weights -= self.learning_rate * gradient_weights\n",
        "            self.bias -= self.learning_rate * gradient_bias\n",
        "\n",
        "            # Apply learning rate decay\n",
        "            self.learning_rate *= self.learning_rate_decay\n",
        "\n",
        "            if epoch % 100 == 0 or epoch == self.epochs - 1:\n",
        "                # Calculate the cross-entropy loss\n",
        "                loss = -np.mean(np.sum(y_onehot * np.log(probs + 1e-9), axis=1))\n",
        "                print(f'Epoch {epoch}, Loss: {loss:.4f}')\n",
        "\n",
        "    def predict(self, test_data_csv: str) -> numpy.ndarray:\n",
        "        \"\"\"\n",
        "        Predict class labels for test data using the trained multinomial logistic regression model.\n",
        "\n",
        "        Loads the test data from a CSV file into a pandas DataFrame. Then, computes the softmax probabilities for each\n",
        "        class using the dot product of the feature matrix and the model weights. The class label for each instances is\n",
        "        predicted based on the highest probability using argmax.\n",
        "\n",
        "        Parameters:\n",
        "            test_data_csv (str): File path to the CSV file containing test data.\n",
        "\n",
        "        Returns:\n",
        "            numpy.ndarray: Predicted class labels for the test data.\n",
        "        \"\"\"\n",
        "        # TODO\n",
        "        # Load test data\n",
        "        test_data = pd.read_csv(test_data_csv)\n",
        "        X_test = test_data.drop('Label', axis=1).values\n",
        "        true_labels_encoded = self.label_encoder.transform(test_data['Label'])\n",
        "        logits = np.dot(X_test, self.weights.T) + self.bias\n",
        "        probs = self.softmax(logits)\n",
        "        predictions_encoded = np.argmax(probs, axis=1)\n",
        "\n",
        "        self.predictions_encoded = predictions_encoded\n",
        "        self.true_labels_encoded = true_labels_encoded\n",
        "        return self.label_encoder.inverse_transform(predictions_encoded)\n",
        "\n",
        "    def initialize(self, training_data_csv):\n",
        "        self.training_data = pd.read_csv(training_data_csv)\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        # Fit the label encoder and transform the 'Label' column to get encoded labels\n",
        "        self.training_data['Label'] = self.label_encoder.fit_transform(self.training_data['Label'])\n",
        "        self.num_classes = len(self.label_encoder.classes_)\n",
        "        self.num_features = self.training_data.drop('Label', axis=1).shape[1]\n",
        "        self.weights = np.zeros((self.num_classes, self.num_features))\n",
        "        self.bias = np.zeros(self.num_classes)\n",
        "\n",
        "    def generate_report(self):\n",
        "        if hasattr(self, 'predictions_encoded') and hasattr(self, 'true_labels_encoded'):\n",
        "            true_labels = self.label_encoder.inverse_transform(self.true_labels_encoded)\n",
        "            predictions = self.label_encoder.inverse_transform(self.predictions_encoded)\n",
        "\n",
        "            report = classification_report(true_labels, predictions)\n",
        "            print(report)\n",
        "        else:\n",
        "            raise ValueError(\"Predictions or true labels are not available. Please run predict() first.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnZp71mtKlpL",
        "outputId": "9710a83e-2ec4-4902-967a-25a48e22f61e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 14.3065\n",
            "Epoch 99, Loss: 19.2726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.00      0.00      0.00        11\n",
            "      B-MISC       0.00      0.00      0.00        35\n",
            "       B-ORG       0.00      0.00      0.00        24\n",
            "       I-LOC       0.00      0.00      0.00      8286\n",
            "      I-MISC       0.00      0.00      0.00      4558\n",
            "       I-ORG       0.00      0.00      0.00     10001\n",
            "       I-PER       0.00      0.00      0.00     11128\n",
            "           O       0.83      1.00      0.91    170524\n",
            "\n",
            "    accuracy                           0.83    204567\n",
            "   macro avg       0.10      0.12      0.11    204567\n",
            "weighted avg       0.69      0.83      0.76    204567\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "multiClassifier = MultinomialLogisticRegression(0.001, 1.0, 100, \"training.csv\")\n",
        "multiClassifier.learn()\n",
        "multiClassifier.predict(\"training.csv\")\n",
        "multiClassifier.generate_report()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multiClassifier.predict(\"testing.csv\")\n",
        "multiClassifier.generate_report()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nRLCetJqUu8",
        "outputId": "976d189b-cd3b-4184-f3a9-81c94e8e393e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      B-MISC       0.00      0.00      0.00         4\n",
            "       I-LOC       0.00      0.00      0.00      2094\n",
            "      I-MISC       0.00      0.00      0.00      1264\n",
            "       I-ORG       0.00      0.00      0.00      2092\n",
            "       I-PER       0.00      0.00      0.00      3149\n",
            "           O       0.83      1.00      0.91     42975\n",
            "\n",
            "    accuracy                           0.83     51578\n",
            "   macro avg       0.14      0.17      0.15     51578\n",
            "weighted avg       0.69      0.83      0.76     51578\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multiClassifier.predict(\"testingB.csv\")\n",
        "multiClassifier.generate_report()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlwnG7WpqaRs",
        "outputId": "b9e3913f-39d9-4ce9-821b-5d736c8eb7ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.00      0.00      0.00         6\n",
            "      B-MISC       0.00      0.00      0.00         9\n",
            "       B-ORG       0.00      0.00      0.00         5\n",
            "       I-LOC       0.00      0.00      0.00      1919\n",
            "      I-MISC       0.00      0.00      0.00       909\n",
            "       I-ORG       0.00      0.00      0.00      2491\n",
            "       I-PER       0.00      0.00      0.00      2773\n",
            "           O       0.83      1.00      0.90     38554\n",
            "\n",
            "    accuracy                           0.83     46666\n",
            "   macro avg       0.10      0.12      0.11     46666\n",
            "weighted avg       0.68      0.83      0.75     46666\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"testingB.csv\")\n",
        "label_counts = df['Label'].value_counts()\n",
        "print(label_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANgPfPf3fdot",
        "outputId": "b8ee1d7c-2ae3-4b82-c88a-f9e5cbeb58b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O         38554\n",
            "I-PER      2773\n",
            "I-ORG      2491\n",
            "I-LOC      1919\n",
            "I-MISC      909\n",
            "B-MISC        9\n",
            "B-LOC         6\n",
            "B-ORG         5\n",
            "Name: Label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoKCA6kTirOI"
      },
      "source": [
        "Reporting the results of a multiclass classification is a little more complicated than binary classification. For this part, [please read the documentation of scikit-learn's `classification_report`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html).\n",
        "\n",
        "Then, add an instance method called `generate_report` to the above class. This method should take no arguments (other than the default `self`), and print the report for your classification results in the same format as shown in the above documentation. That is, for a 3-class classification, it should print (shown with dummy results):\n",
        "\n",
        "```\n",
        "                precision    recall  f1-score   support\n",
        "\n",
        "     class 0       0.50      1.00      0.67         1\n",
        "     class 1       0.00      0.00      0.00         1\n",
        "     class 2       1.00      0.67      0.80         3\n",
        "\n",
        "    accuracy                           0.60         5\n",
        "   macro avg       0.50      0.56      0.49         5\n",
        "   micro avg       1.00      0.67      0.80         5\n",
        "```\n",
        "\n",
        "In your generated report, the class names must be the actual labels (e.g., `I-PER`) and not just numbers or indices. As you may have realized, your method will simply be a wrapper around scikit-learn's `classification_report`, but you will have to carefully think about the parameter values to use.\n",
        "\n",
        "**Note:** You are not responsible for generating a report if a user calls this method before testing (by a call to the `predict` function). If a user does invoke `generate_report` without invoking `predict` first, it is acceptable for your code to raise an error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhNUPSG4mha5"
      },
      "source": [
        "# Your insights [20 points]\n",
        "\n",
        "## 1. Test set vs Dev set: Binary classification [4 points]\n",
        "\n",
        "For the binary classification task, how much does the performance (in terms of each metric) differ between the dev set and the final test set?\n",
        "\n",
        "**Precision: Difference: 0.960968 - 0.949935 = 0.011033**<br>\n",
        "**Recall: Difference: 0.793725 - 0.781836 = 0.011890**<br>\n",
        "**F1 Score: Difference: 0.864833 - 0.862196 = 0.002637** â€‹<br><br>\n",
        "  **These differences indicate that the model's ability to correctly classify positive instances (precision) has decreased slightly in the test set, but its ability to identify all positive instances (recall) has increased marginally. The overall F1 score, which balances precision and recall, is slightly lower on the test set, suggesting a small drop in the model's overall performance from the dev set to the test set.**\n",
        "\n",
        "What do you think are the causes behind these differences?\n",
        "\n",
        "> **The differences in performance metrics between the development (dev) set and the test set can be attributed to several factors:**<br>\n",
        "**1. Data Distribution**<br>\n",
        "**2. Feature Representation:**<br>\n",
        "**3. Class Imbalance:<br>**\n",
        "\n",
        ">**But after taking a look at the data I think it is class imbalance because there is a little difference between the occurance of different classes.**\n",
        "\n",
        "Suggest one or two experiments that you should design and conduct, in order to test your hypothesis (i.e., in order to test whether your answer to the above question is, indeed, correct).\n",
        "\n",
        "> **So I just tried printing the occurances of each element in the Label's column and there is a slight difference. May be that slight difference is causing that slight difference in F-1 Scores.**\n",
        "\n",
        "## 2. Stochastic Gradient Descent [10 points]\n",
        "\n",
        "### What exactly is an epoch?\n",
        "\n",
        ">**An epoch in the context of stochastic gradient descent (SGD) is one complete pass through the entire training dataset. During an epoch, the model iterates over all training examples, updating its parameters based on the gradients computed for each example or batch of examples.**\n",
        "\n",
        "### Why is it important to optimize over multiple epochs, when in each epoch, the training is happening over the same data?\n",
        "\n",
        ">**Optimizing over multiple epochs is important because it allows the model to refine its parameters iteratively. In each epoch, the model has the opportunity to adjust its weights based on the errors it made in the previous epoch. This iterative process helps the model to converge to a set of parameters that minimize the loss function.**\n",
        "\n",
        "### For the binary classification task, what regularization did you choose when optimizing? Why did you choose this, and not any other?\n",
        "\n",
        ">**For the binary classification task, I chose L2 regularization when optimizing. L2 regularization, adds a penalty term to the loss function proportional to the square of the magnitude of the weights. I chose L2 regularization because it tends to produce models with smaller and more spread-out weights, which can help prevent overfitting and improve generalization.**\n",
        "\n",
        "### For the multiclass classification task, what regularization did you choose when optimizing? Why did you choose this, and not any other?\n",
        "\n",
        "> **For the multiclass classification task in my NLP project, I chose L2 regularization as the optimization method. I selected L2 regularization because it effectively prevents overfitting by adding a penalty term to the loss function. This penalty is proportional to the square of the magnitude of the coefficients, which encourages the model to maintain smaller weights. This approach can lead to a more generalizable model, as it discourages the model from relying too heavily on any single feature and helps to manage the complexity of the model.**\n",
        "\n",
        "\n",
        "\n",
        "### What types of learning rate decay were included in your experiments (as discussed in the lecture before Spring break)? Did the dev set play an important role in these experiments? Briefly explain how. Also briefly explain what made you fix the type of learning rate decay when testing on the final test set.\n",
        "\n",
        "> **In my experiments with logistic regression for NLP, I included exponential and time-based learning rate decay methods. The development (dev) set played a crucial role in these experiments as it allowed me to tune the hyperparameters, such as the learning rate and decay rate, without overfitting to the test set. By evaluating the performance on the dev set, I could adjust the learning rate decay parameters to achieve a balance between learning speed and model stability.<br>\n",
        "I fixed the type of learning rate decay when testing on the final test set based on the results obtained from the dev set. I chose the decay type that provided the best balance between convergence speed and model performance on the dev set. This approach ensured that the model was neither learning too slowly nor oscillating too much around the optimal solution, leading to better generalization on unseen data.**\n",
        "\n",
        "\n",
        "\n",
        "## 3. Multiclass classification [6 points]\n",
        "\n",
        "###Were there any classes that were particularly hard to detect?\n",
        "\n",
        ">**Based on the report I've examined, it looks like my model has had a tough time identifying any classes other than \"O\". Every other class has zeroed out on precision, recall, and F1-score, which tells me that my model hasn't correctly identified a single instance of those classes.<br>\n",
        "Here's why I think these classes were difficult for the model to identify:<br>\n",
        "The \"O\" class appears to be heavily overrepresented, which may have caused the model to become biased towards predicting \"O\" and neglecting the other categories.<br>\n",
        "My model might not have been trained effectively, either due to due to the imbalance in the dataset as I have tried to convered the dataset into IOB2 which was not giving different results.\n",
        "**\n",
        "\n",
        "###Why do you think these classes were comparatively more difficult to identify correctly?\n",
        "\n",
        ">**To improve performance on these more challenging categories, I would conduct several experiments: <br>\n",
        "Balancing the Dataset: I would experiment with data balancing techniques such as oversampling the minority classes or undersampling the majority class. Balancing should provide a more uniform distribution of classes for the model to learn from.<br>\n",
        "Enhancing Feature Engineering: I would try out different features or look into more sophisticated representations like word embeddings or even contextual embeddings from transformer models, which might capture the nuances of language better.<br>\n",
        "Adjusting Model Complexity: I would assess whether my model is complex enough to capture the data's diversity. If it's too simplistic, that could be a problem, so I might consider making it more complex, possibly exploring deep learning approaches.\n",
        "Hyperparameter Optimization: I would perform a thorough search for the optimal set of hyperparameters, including the learning rate and regularization strength, to see if any adjustments lead to better model performance.**\n",
        "\n",
        "###What experiments would you design and conduct to try and improve the performance on these difficult categories? Support your answer with technical reasoning (in this context, \"technical\" means either based on mathematical reasoning, linguistic insights, or statistical insights drawn from data).\n",
        "\n",
        "> **To tackle the issue of my model's poor performance on certain classes, I would design and conduct the following experiment by these technical reasoning:<br>\n",
        "Class Rebalancing Experiment: First, I would adjust the class distribution in my training data since the support numbers suggest a large imbalance. I will either augment the minority classes by synthesizing new data points using techniques like SMOTE or by simply duplicating existing ones. Also, I might also try down-sampling the \"O\" class. The technical reasoning here is based on statistical learning theory which suggests that models trained on balanced datasets are less biased towards the majority class.<br>\n",
        "Feature Engineering Experiment: I would hypothesize that the current features might not capture the cues necessary for NER. Thus, I would experiment with linguistic features such as part-of-speech tags, word embeddings, and perhaps position embeddings to give the model more contextual information. Mathematically, richer feature vectors can help in defining more complex decision boundaries, making it easier to distinguish between different classes.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCRYJECGvJyA"
      },
      "source": [
        "# Collaboration Policy\n",
        "\n",
        "You may discuss any details of this assignment at a conceptual level with anyone. In fact, discussion of ideas and helping each other to gain a better understanding of the concepts and the mathematical principles is encouraged. But any written answers (natural language or programming language) must be entirely your own original work.\n",
        "\n",
        "- There must not be any collaboration in programming (including the design, implementation, and debugging of code).\n",
        "- There must not be any code in your submission that is written by anyone other than you (whether human or AI).\n",
        "  - Submitted code will be checked against other submissions AND against AI-generated code, and evidence of plagiarism will lead to academic dishonesty charges.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgzO7l66vqr8"
      },
      "source": [
        "# What to submit?\n",
        "\n",
        "1.  Make your colab notebook publicly accessible. You can do this by clicking \"Share\" on the top-right corner of your notebook and make sure \"anyone with the link\" can view your notebook. Also make sure that viewers are allowed to download your notebook. Then, **put this link in the comment section of your submission on Brightspace**.\n",
        "2.  Create an empty folder (locally, on your computer) called `firstname-lastname-cse354-hw2`. For example, John Doe will create `john-doe-cse354-hw2`.\n",
        "  * Download this colab notebook with all the questions (code as well as the text questions) implemented/answered. This will be a single Python notebook, as a `.ipynb` file. Put the notebook in your folder.\n",
        "  \n",
        "  Zip this folder (i.e., create `firstname-lastname-cse354-hw2.zip`) and submit on Brightspace.\n",
        "\n",
        "Once unzipped, your submission is expcted to have the following structure:\n",
        "\n",
        "```\n",
        "john-doe-cse354-hw2\n",
        "â”œâ”€â”€ CSE354-Assignment-2.ipynb\n",
        "â””â”€â”€ README.md (optional)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77zUcnqvw_oe"
      },
      "source": [
        "# Important Notes\n",
        "\n",
        "- Write comments to make your code readable. The short-term benefit is that if your code is doing something wrong, members of the teaching staff can consult your comments to see if the attempt was in the right direction (for potential partial credit). The long-term benefit is that you get into the habit of writing code that had good human readability, including your own future self!\n",
        "- **DO NOT change any code already given to you** (except potentially in one or two places where exceptions have been clearly articulated). This includes the limitations imposed on the use of external libraries, the method signatures, the data types specified through type hints, the return types, and the descriptions provided in docstrings.\n",
        "\n",
        "Next, is an example use of your code. This is not the only way to run your code, but it is provided here as an example of how you might want to check the various components of your code (whether you are developing locally on your computer or directly working on colab). As you can see, this is only an outline (for example, there is no use of a dev set in this example code snippet). As the developer of this NER application, you should perform much more extensive testing and debugging to ensure correctness of this application.\n",
        "\n",
        "```\n",
        "# Data preparation: creating the CSV files\n",
        "create_dataframe(dataloader.ActionType.TRAIN, 'train_set.csv')\n",
        "create_dataframe(dataloader.ActionType.TEST, 'test_set.csv')\n",
        "\n",
        "# Model training\n",
        "model = MultinomialLogisticRegression(learning_rate=0.05, epochs=5, training_data_csv='train_set.csv')\n",
        "model.learn()\n",
        "\n",
        "# Model testing and report generation\n",
        "predictions: numpy.ndarray = model.predict(test_data_csv='test_set.csv')\n",
        "model.generate_report()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNkWLUXx0yL7"
      },
      "source": [
        "# Due date\n",
        "\n",
        "## **11:59 pm, March 26 (Tuesday)**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}